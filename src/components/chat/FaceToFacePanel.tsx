"use client";

import { useEffect, useMemo, useRef, useState } from "react";

type Props = {
  userId?: string;
  lang?: "en" | "es";
  wantVoice?: boolean;
  onVoiceNotice?: (msg: string | null) => void;
};

type TurnResponse = {
  ok?: boolean;
  transcript?: string;
  reply?: string;
  tts?: { audioUrl?: string; provider?: string; seconds?: number } | null;
  voiceBlocked?: boolean;
  voiceReason?: "login_required" | "temporarily_unavailable" | string | null;
  error?: string;
};

function pickMimeCandidates() {
  return [
    "audio/webm;codecs=opus",
    "audio/webm",
    "audio/ogg;codecs=opus",
    "audio/ogg",
    "audio/mp4", // Safari –∏–Ω–æ–≥–¥–∞
  ];
}

function extFromMime(mime: string) {
  const m = (mime || "").toLowerCase();
  if (m.includes("ogg")) return "ogg";
  if (m.includes("mp4")) return "mp4";
  return "webm";
}

export default function FaceToFacePanel({
  userId,
  lang = "en",
  wantVoice = true,
  onVoiceNotice,
}: Props) {
  const videoRef = useRef<HTMLVideoElement | null>(null);

  const streamRef = useRef<MediaStream | null>(null); // preview audio+video
  const audioOnlyRef = useRef<MediaStream | null>(null); // recorder only audio

  const ttsAudioRef = useRef<HTMLAudioElement | null>(null);

  const recorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<BlobPart[]>([]);

  const stopGuardTimerRef = useRef<number | null>(null);

  const [camReady, setCamReady] = useState(false);
  const [recState, setRecState] = useState<"idle" | "recording" | "sending">("idle");

  const [lastTranscript, setLastTranscript] = useState("");
  const [lastReply, setLastReply] = useState("");
  const [localNotice, setLocalNotice] = useState<string | null>(null);

  const [autoTalk, setAutoTalk] = useState(true);

  const audioCtxRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const vadRafRef = useRef<number | null>(null);

  const speechOnAtRef = useRef<number | null>(null);
  const silenceOnAtRef = useRef<number | null>(null);

  const localeText = useMemo(() => {
    const isEs = lang === "es";
    return {
      title: "Call",
      subtitle: isEs ? "Toca para hablar con Mindra" : "Tap to talk with Mindra",
      tap: isEs ? "Tocar para hablar" : "Tap to talk",
      stop: isEs ? "Detener" : "Stop",
      sending: isEs ? "Enviando‚Ä¶" : "Sending‚Ä¶",
      loading: isEs ? "Cargando c√°mara‚Ä¶" : "Loading camera‚Ä¶",
      noMic: isEs ? "Acceso al micr√≥fono denegado" : "Microphone access denied",
      noCam: isEs ? "Acceso a la c√°mara denegado" : "Camera access denied",
      recNoSupport: isEs ? "Grabaci√≥n no soportada" : "Recording is not supported",
      youSaid: isEs ? "T√∫ dijiste:" : "You said:",
      mindra: isEs ? "Mindra:" : "Mindra:",
      signIn: isEs ? "Inicia sesi√≥n para usar voz premium." : "Please sign in to use premium voice.",
      unavailable: isEs ? "La voz premium no est√° disponible ahora." : "Premium voice is not available right now.",
      recError: isEs ? "No pude iniciar la grabaci√≥n üôà" : "Could not start recording üôà",
      stopError: isEs ? "No pude detener la grabaci√≥n üôà" : "Could not stop recording üôà",
      empty: isEs ? "No capt√© audio üôà" : "No audio captured üôà",
    };
  }, [lang]);

  useEffect(() => {
  let mounted = true;

  const start = async () => {
    try {
      setLocalNotice(null);

      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "user" },
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      });

      if (!mounted) return;

      streamRef.current = stream;
      audioOnlyRef.current = new MediaStream(stream.getAudioTracks());

      // ‚úÖ —Å—Ç–∞—Ä—Ç—É–µ–º VAD —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –∞—É–¥–∏–æ
      startVAD(audioOnlyRef.current);

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        await videoRef.current.play().catch(() => {});
      }

      setCamReady(true);
    } catch (e) {
      console.log("[CALL] getUserMedia error:", e);
      setCamReady(false);
      setLocalNotice(localeText.noCam);
    }
  };

  start();

  return () => {
    mounted = false;

    // ‚úÖ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å VAD
    stopVAD();

    try {
      if (recorderRef.current && recorderRef.current.state !== "inactive") {
        recorderRef.current.stop();
      }
    } catch {}
    recorderRef.current = null;

    if (stopGuardTimerRef.current) {
      window.clearTimeout(stopGuardTimerRef.current);
      stopGuardTimerRef.current = null;
    }

    try {
      streamRef.current?.getTracks().forEach((t) => t.stop());
    } catch {}

    streamRef.current = null;
    audioOnlyRef.current = null;
  };
  // eslint-disable-next-line react-hooks/exhaustive-deps
}, []);


  const createRecorder = (stream: MediaStream) => {
    if (typeof MediaRecorder === "undefined") return null;

    // –∫–∞–Ω–¥–∏–¥–∞—Ç—ã
    for (const mt of pickMimeCandidates()) {
      try {
        if (MediaRecorder.isTypeSupported(mt)) {
          return new MediaRecorder(stream, { mimeType: mt });
        }
      } catch {}
    }

    // fallback –±–µ–∑ mimeType
    try {
      return new MediaRecorder(stream);
    } catch {
      return null;
    }
  };

  const stopTts = () => {
  const a = ttsAudioRef.current;
  if (!a) return;

  try {
    a.pause();
    a.currentTime = 0;
  } catch {}

  ttsAudioRef.current = null;
};


  const stopVAD = () => {
    if (vadRafRef.current) {
      cancelAnimationFrame(vadRafRef.current);
      vadRafRef.current = null;
    }
    try {
      analyserRef.current?.disconnect();
    } catch {}
    analyserRef.current = null;

    try {
      audioCtxRef.current?.close();
    } catch {}
    audioCtxRef.current = null;

    speechOnAtRef.current = null;
    silenceOnAtRef.current = null;
  };

  const startVAD = (stream: MediaStream) => {
    // iOS/Safari: AudioContext —á–∞—Å—Ç–æ —Ç—Ä–µ–±—É–µ—Ç user gesture.
    // –ú—ã –∑–∞–ø—É—Å—Ç–∏–º, –Ω–æ –µ—Å–ª–∏ –±—É–¥–µ—Ç suspended ‚Äî –ø—Ä–æ—Å—Ç–æ –ø–æ–ø—Ä–æ–±—É–µ–º resume –ø—Ä–∏ –∫–ª–∏–∫–µ (–Ω–∏–∂–µ –¥–æ–±–∞–≤–∏–º).
    stopVAD();

    try {
      const AudioCtx = (window.AudioContext || (window as any).webkitAudioContext);
      const ctx: AudioContext = new AudioCtx();
      audioCtxRef.current = ctx;

      const src = ctx.createMediaStreamSource(stream);
      const analyser = ctx.createAnalyser();
      analyser.fftSize = 1024;
      analyser.smoothingTimeConstant = 0.8;
      analyserRef.current = analyser;

      src.connect(analyser);

      const buf = new Uint8Array(analyser.fftSize);

      // --- —Ç—é–Ω–∏–Ω–≥ –ø–æ—Ä–æ–≥–æ–≤ ---
      const START_THRESHOLD = 0.018; // —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—Ç–∞—Ä—Ç–∞ (rms)
      const STOP_THRESHOLD  = 0.012; // –ø–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã (rms)
      const START_HOLD_MS   = 120;   // —Å–∫–æ–ª—å–∫–æ –¥–µ—Ä–∂–∞—Ç—å "–≥—Ä–æ–º–∫–æ" —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å
      const SILENCE_MS      = 700;   // —Å–∫–æ–ª—å–∫–æ —Ç–∏—à–∏–Ω—ã —á—Ç–æ–±—ã –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å

      const loop = () => {
        vadRafRef.current = requestAnimationFrame(loop);

        if (!autoTalk) return;
        if (!analyserRef.current) return;

        // –∫–æ–≥–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º ‚Äî –Ω–µ —Ç—Ä–æ–≥–∞–µ–º –∑–∞–ø–∏—Å—å
        if (recState === "sending") return;

        // –±–µ—Ä—ë–º —Å–∏–≥–Ω–∞–ª
        analyserRef.current.getByteTimeDomainData(buf);

        // RMS
        let sum = 0;
        for (let i = 0; i < buf.length; i++) {
          const v = (buf[i] - 128) / 128;
          sum += v * v;
        }
        const rms = Math.sqrt(sum / buf.length);
        const now = performance.now();

        const isRecording = recorderRef.current?.state === "recording";

        // --- START logic ---
        if (!isRecording) {
          if (rms >= START_THRESHOLD) {
            if (speechOnAtRef.current == null) speechOnAtRef.current = now;
            const held = now - speechOnAtRef.current;

            if (held >= START_HOLD_MS) {
              // –Ω–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å
              silenceOnAtRef.current = null;
              speechOnAtRef.current = null;
              startRecording();
            }
          } else {
            speechOnAtRef.current = null;
          }
          return;
        }

        // --- STOP logic (–∫–æ–≥–¥–∞ –ø–∏—à–µ–º) ---
        if (rms <= STOP_THRESHOLD) {
          if (silenceOnAtRef.current == null) silenceOnAtRef.current = now;
          const silentFor = now - silenceOnAtRef.current;

          if (silentFor >= SILENCE_MS) {
            silenceOnAtRef.current = null;
            stopRecording();
          }
        } else {
          silenceOnAtRef.current = null;
        }
      };

      loop();
    } catch (e) {
      console.log("[CALL] VAD start error:", e);
      stopVAD();
    }
  };


  const startRecording = async () => {
    try {
      stopTts();
      setLocalNotice(null);
      onVoiceNotice?.(null);

      if (recState === "sending") return;
      if (!audioOnlyRef.current) {
        setLocalNotice(localeText.noMic);
        return;
      }
      if (typeof MediaRecorder === "undefined") {
        setLocalNotice(localeText.recNoSupport);
        return;
      }
      if (recorderRef.current && recorderRef.current.state === "recording") return;

      chunksRef.current = [];

      const mr = createRecorder(audioOnlyRef.current);
      if (!mr) {
        setLocalNotice(localeText.recNoSupport);
        return;
      }

      mr.ondataavailable = (ev) => {
        if (ev.data && ev.data.size > 0) chunksRef.current.push(ev.data);
      };

      mr.onstop = async () => {
        // ‚úÖ –í–ê–ñ–ù–û: –∏–º–µ–Ω–Ω–æ –∑–¥–µ—Å—å –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è "sending"
        setRecState("sending");

        // —Å—Ç–æ–ø-—Ç–∞–π–º–µ—Ä –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–µ–Ω
        if (stopGuardTimerRef.current) {
          window.clearTimeout(stopGuardTimerRef.current);
          stopGuardTimerRef.current = null;
        }

        try {
          const usedMime = mr.mimeType || "audio/webm";
          const blob = new Blob(chunksRef.current, { type: usedMime });
          chunksRef.current = [];

          if (!blob || blob.size < 2000) {
            setLocalNotice(localeText.empty);
            setRecState("idle");
            return;
          }

          await sendTurn(blob, usedMime);
        } catch (e) {
          console.log("[CALL] onstop error:", e);
          setLocalNotice("Server error üòï");
          setRecState("idle");
        }
      };

      recorderRef.current = mr;
      setRecState("recording");

      // ‚úÖ timeslice –ø–æ–º–æ–≥–∞–µ—Ç, —á—Ç–æ–±—ã dataavailable —Ç–æ—á–Ω–æ –ø—Ä–∏–ª–µ—Ç–∞–ª
      mr.start(250);
    } catch (e) {
      console.log("[CALL] recorder start error:", e);
      setLocalNotice(localeText.recError);
      setRecState("idle");
    }
  };

  const stopRecording = () => {
    try {
      const r = recorderRef.current;

      // ‚úÖ –µ—Å–ª–∏ —Ä–µ–∞–ª—å–Ω–æ –Ω–µ –ø–∏—à–µ–º ‚Äî –Ω–µ –∑–∞–≤–∏—Å–∞–µ–º
      if (!r || r.state !== "recording") {
        setRecState("idle");
        return;
      }

      // ‚úÖ —Å—Ç—Ä–∞—Ö–æ–≤–∫–∞: –µ—Å–ª–∏ onstop –Ω–µ –ø—Ä–∏–¥—ë—Ç –∑–∞ 2.5 —Å–µ–∫ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º UI
      if (stopGuardTimerRef.current) window.clearTimeout(stopGuardTimerRef.current);
      stopGuardTimerRef.current = window.setTimeout(() => {
        console.log("[CALL] stop guard fired (onstop not received)");
        setLocalNotice(localeText.stopError);
        setRecState("idle");
        try {
          if (recorderRef.current && recorderRef.current.state !== "inactive") {
            recorderRef.current.stop();
          }
        } catch {}
      }, 2500);

      r.stop();
      // ‚ùó –ù–ï —Å—Ç–∞–≤–∏–º sending –∑–¥–µ—Å—å
    } catch (e) {
      console.log("[CALL] stopRecording error:", e);
      setLocalNotice(localeText.stopError);
      setRecState("idle");
    }
  };

  const toggleRecording = () => {
    if (recState === "recording") stopRecording();
    else startRecording();
  };

  const sendTurn = async (audioBlob: Blob, mime: string) => {
    const uid = userId || "web";
    const want = wantVoice ? "1" : "0";

    try {
      const fd = new FormData();

      const ext = extFromMime(mime || audioBlob.type || "audio/webm");
      const fileName = `turn.${ext}`;
      const file = new File([audioBlob], fileName, { type: audioBlob.type || mime || "audio/webm" });

      fd.append("audio", file);
      fd.append("user_id", uid);
      fd.append("sessionId", "call");
      fd.append("feature", "call");
      fd.append("lang", lang);
      fd.append("wantVoice", want);

      // ‚úÖ –í–æ—Ç —Ç—É—Ç –î–û–õ–ñ–ï–ù –ø–æ—è–≤–∏—Ç—å—Å—è /api/call/turn –≤ Network
      const res = await fetch("/api/call/turn", { method: "POST", body: fd });

      const data: TurnResponse = await res.json().catch(() => ({}));

      if (!data || data.ok === false) {
        setLocalNotice(data?.error || "Server error üòï");
        setRecState("idle");
        return;
      }

      setLastTranscript(data.transcript || "");
      setLastReply(data.reply || "");

      if (data.voiceBlocked) {
        if (data.voiceReason === "login_required") {
          setLocalNotice(localeText.signIn);
          onVoiceNotice?.(localeText.signIn);
        } else {
          setLocalNotice(localeText.unavailable);
          onVoiceNotice?.(localeText.unavailable);
        }
      } else {
        setLocalNotice(null);
        onVoiceNotice?.(null);
      }

      const ttsUrl = data?.tts?.audioUrl;
if (ttsUrl) {
  try {
    stopTts(); // –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π

    const a = new Audio(ttsUrl);
    a.preload = "auto";
    a.volume = 1.0;

    a.onended = () => {
      if (ttsAudioRef.current === a) ttsAudioRef.current = null;
    };

    ttsAudioRef.current = a;
    a.play().catch(() => {});
  } catch {}
}



      setRecState("idle");
    } catch (e) {
      console.log("[CALL] sendTurn error:", e);
      setLocalNotice("Server error üòï");
      setRecState("idle");
    }
  };

  return (
    <div
    className="flex-1 overflow-y-auto"
    onPointerDown={() => {
      const ctx = audioCtxRef.current;
      if (ctx && ctx.state === "suspended") {
        ctx.resume().catch(() => {});
      }
    }}
  >
      <div className="mx-auto max-w-3xl px-6 py-6">
        <div className="mb-4">
          <div className="text-2xl font-semibold">{localeText.title}</div>
          <div className="text-sm text-[var(--muted)]">{localeText.subtitle}</div>
        </div>

        <div className="rounded-2xl border border-[var(--border)] bg-[var(--panel)] p-4">
          <div className="relative overflow-hidden rounded-2xl bg-black/30">
            <video ref={videoRef} playsInline muted className="h-[340px] w-full object-cover" />

            {!camReady ? (
              <div className="absolute inset-0 grid place-items-center text-sm text-[var(--muted)]">
                {localNotice || localeText.loading}
              </div>
            ) : null}

            <div className="absolute inset-x-0 bottom-4 flex justify-center">
              <button
                onClick={toggleRecording}
                className={[
                  "rounded-full px-5 py-2 text-sm font-medium",
                  "border border-[var(--border)]",
                  "bg-[var(--btn)] hover:bg-[var(--btnHover)]",
                  "text-white shadow",
                  recState === "recording" ? "scale-[1.03]" : "",
                ].join(" ")}
              >
                {recState === "sending"
                  ? localeText.sending
                  : recState === "recording"
                  ? `‚óè ${localeText.stop}`
                  : localeText.tap}
              </button>
            </div>
          </div>

          {(lastTranscript || lastReply) && (
            <div className="mt-4 space-y-3">
              {lastTranscript ? (
                <div className="rounded-xl border border-[var(--border)] bg-black/20 p-3">
                  <div className="text-xs text-[var(--muted)] mb-1">{localeText.youSaid}</div>
                  <div className="text-sm">{lastTranscript}</div>
                </div>
              ) : null}

              {lastReply ? (
                <div className="rounded-xl border border-[var(--border)] bg-black/20 p-3">
                  <div className="text-xs text-[var(--muted)] mb-1">{localeText.mindra}</div>
                  <div className="text-sm whitespace-pre-wrap">{lastReply}</div>
                </div>
              ) : null}

              {localNotice ? (
                <div className="text-xs text-[var(--muted)] text-right">{localNotice}</div>
              ) : null}
            </div>
          )}
        </div>
      </div>
    </div>
  );
}
